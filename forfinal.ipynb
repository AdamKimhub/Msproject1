{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AdamKimhub/Msproject1/blob/colab/forfinal.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1c20f759",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1c20f759",
        "outputId": "f65de842-1faa-4a18-9778-9343225d37ef"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "\n",
        "if \"google.colab\" in sys.modules:\n",
        "    # Mount Google Drive\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "    dataset_path = '/content/drive/My Drive/dataset'\n",
        "\n",
        "    # Install required packages\n",
        "    !pip install pymatgen torch_geometric\n",
        "    import torch\n",
        "    from torch_geometric.data import Data\n",
        "\n",
        "else:\n",
        "    dataset_path = 'dataset'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a10ddae3",
      "metadata": {
        "id": "a10ddae3"
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "import ast\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pymatgen.core import Structure, PeriodicSite, DummySpecie\n",
        "from pymatgen.analysis.local_env import MinimumDistanceNN\n",
        "\n",
        "import to_graph"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7aaaa3c2",
      "metadata": {
        "id": "7aaaa3c2"
      },
      "source": [
        "## For Highly Concentrated Defects Datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c89c9596",
      "metadata": {
        "id": "c89c9596"
      },
      "outputs": [],
      "source": [
        "high_dataset = [\"high_BN\", \"high_GaSe\", \"high_InSe\", \"high_MoS2\", \"high_P\", \"high_WSe2\"]\n",
        "to_merge = [pd.read_csv(f\"{dataset_path}/combined/{high_data}.csv\") for high_data in high_dataset]\n",
        "\n",
        "high_df  = pd.concat(to_merge, ignore_index=True)\n",
        "\n",
        "high_copy = high_df.copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d1708d37",
      "metadata": {
        "id": "d1708d37"
      },
      "outputs": [],
      "source": [
        "high_copy = high_copy.drop([\"_id\", \"base\", \"cell\", \"dataset_material\", \"fermi_level\", \"total_mag\"], axis =1)\n",
        "high_copy = high_copy.corr()\n",
        "high_copy"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b2a1865b",
      "metadata": {
        "id": "b2a1865b"
      },
      "source": [
        "## For Lowly Concentrated Defects Datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b7e760af",
      "metadata": {
        "id": "b7e760af"
      },
      "outputs": [],
      "source": [
        "low_dataset = [\"low_MoS2\", \"low_WSe2\"]\n",
        "to_merge = [pd.read_csv(f\"{dataset_path}/combined/{low_data}.csv\") for low_data in low_dataset]\n",
        "\n",
        "low_df  = pd.concat(to_merge, ignore_index=True)\n",
        "\n",
        "low_copy = low_df.copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9bfc90c1",
      "metadata": {
        "id": "9bfc90c1"
      },
      "outputs": [],
      "source": [
        "low_copy = low_copy.drop([\"_id\", \"base\", \"cell\", \"dataset_material\", \"fermi_level\", \"total_mag\"], axis =1)\n",
        "low_copy = low_copy.corr()\n",
        "low_copy"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fc047800",
      "metadata": {
        "id": "fc047800"
      },
      "source": [
        "## For High and Low Concentrations of Defects Datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6d47c380",
      "metadata": {
        "id": "6d47c380"
      },
      "outputs": [],
      "source": [
        "# Read file\n",
        "comb_df = pd.read_csv(f\"{dataset_path}/combined/combined.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9c2cd17d",
      "metadata": {
        "id": "9c2cd17d"
      },
      "outputs": [],
      "source": [
        "comb_copy = comb_df.copy()\n",
        "comb_copy = comb_copy.drop([\"_id\", \"base\", \"cell\", \"dataset_material\", \"fermi_level\", \"total_mag\"], axis =1)\n",
        "comb_copy = comb_copy.corr()\n",
        "comb_copy"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "12b48e12",
      "metadata": {
        "id": "12b48e12"
      },
      "source": [
        "## Data to graphs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9097aca2",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Add strata\n",
        "datsets = [\"high_BN\", \"high_GaSe\", \"high_InSe\", \"high_MoS2\", \"high_P\", \"high_WSe2\",\"low_MoS2\", \"low_WSe2\"]\n",
        "\n",
        "ref_sites_dict = {}\n",
        "\n",
        "for datset in datsets:\n",
        "    mat_split = datset.split('_')\n",
        "    the_base = mat_split[1]\n",
        "\n",
        "    # Get reference structure\n",
        "    ref_unit_cell = Structure.from_file(f\"{dataset_path}/{datset}/{the_base}.cif\")\n",
        "    cell_source = pd.read_csv(f\"{dataset_path}/initial_structures.csv\")\n",
        "    the_cell = cell_source.loc[cell_source[\"base\"] == the_base, \"cell_size\"].iloc[0]\n",
        "    reference_structure = ref_unit_cell.make_supercell(ast.literal_eval(the_cell))\n",
        "\n",
        "    # Get number of ref sites\n",
        "    ref_sites_dict[datset] = reference_structure.num_sites\n",
        "\n",
        "\n",
        "def get_conc(row, ref_sites_dict):\n",
        "    total_num_sites = ref_sites_dict[row[\"dataset_material\"]]\n",
        "\n",
        "    # Get defect conc\n",
        "    defect_conc = round(row[\"defect_sites\"]/total_num_sites,5)\n",
        "    row[\"defect_concentration\"] = defect_conc\n",
        "\n",
        "    # Add material name\n",
        "    row[\"to_strata\"] = f\"{row['base']}_{row['defect_concentration']}\"\n",
        "    return row\n",
        "\n",
        "comb_df = comb_df.apply(lambda row: get_conc(row,ref_sites_dict), axis=1)\n",
        "\n",
        "unique_values = pd.unique(comb_df[\"to_strata\"])\n",
        "mapping = {value: i for i, value in enumerate(unique_values)}\n",
        "\n",
        "comb_df[\"strata\"] = comb_df[\"to_strata\"].map(mapping)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "12096f08",
      "metadata": {},
      "outputs": [],
      "source": [
        "# How about i split the data here\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_set, test_set = train_test_split(comb_df, test_size=0.3, stratify=comb_df['strata'], random_state=42)\n",
        "\n",
        "val_set, testing_set = train_test_split(test_set, test_size=0.5, stratify=test_set['strata'], random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5fb77ab9",
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "def graphy(row):\n",
        "    defective_file_path = Path(f\"{dataset_path}/{row['dataset_material']}/cifs/{row['_id']}.cif\")\n",
        "    defective_structure = Structure.from_file(defective_file_path)\n",
        "\n",
        "    ref_file_path = Path(f\"{dataset_path}/{row['dataset_material']}/{row['base']}.cif\")\n",
        "    ref_unit_cell = Structure.from_file(ref_file_path)\n",
        "    the_cell = ast.literal_eval(row['cell'])\n",
        "    reference_structure = ref_unit_cell.make_supercell(the_cell)\n",
        "\n",
        "    defects_structure = to_graph.get_defects_structure(defective_structure, reference_structure)\n",
        "\n",
        "    the_nodes, the_edges, the_edge_features = to_graph.get_nodes_edges(defects_structure)\n",
        "\n",
        "    global_attributes = [\"energy\",\"fermi_level\",\"total_mag\",\"formation_energy\",\n",
        "                         \"energy_per_atom\",\"E_1\",\"vacancy_sites\", \"substitution_sites\",\n",
        "                         \"defect_sites\", \"defect_concentration\"]\n",
        "    \n",
        "    global_features = [row[i] for i in global_attributes]\n",
        "\n",
        "    target_attribute = \"band_gap_value\"\n",
        "    target_features = [row[target_attribute]]\n",
        "\n",
        "    the_data = Data(x=torch.tensor(the_nodes, dtype=torch.float),\n",
        "                    edge_index=torch.tensor(the_edges, dtype=torch.long),\n",
        "                    edge_attr=torch.tensor(the_edge_features, dtype=torch.float),\n",
        "                    u=torch.tensor(global_features, dtype=torch.float), \n",
        "                    y=torch.tensor(target_features, dtype=torch.float))\n",
        "    return the_data\n",
        "\n",
        "# samplex = samplex_df.apply(lambda row: graphy(row), axis = 1).tolist()\n",
        "\n",
        "# Save the data before splitting\n",
        "# torch.save(samplex, f\"{dataset_path}/combined/all_graphs.pt\")\n",
        "\n",
        "# After splitting, turn them into graph data\n",
        "training = train_set.apply(lambda row: graphy(row), axis = 1).tolist()\n",
        "torch.save(training, f\"{dataset_path}/combined/training.pt\")\n",
        "           \n",
        "validating = val_set.apply(lambda row: graphy(row), axis = 1).tolist()\n",
        "torch.save(validating, f\"{dataset_path}/combined/validating.pt\")\n",
        "\n",
        "testing = testing_set.apply(lambda row: graphy(row), axis = 1).tolist()\n",
        "torch.save(testing, f\"{dataset_path}/combined/testing.pt\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "MsProject",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}

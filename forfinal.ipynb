{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "00c133db",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AdamKimhub/Msproject1/blob/colab/forfinal.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a10ddae3",
      "metadata": {
        "id": "a10ddae3"
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "import ast\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pymatgen.core import Structure, PeriodicSite, DummySpecie\n",
        "from pymatgen.analysis.local_env import MinimumDistanceNN\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0c9356ba",
      "metadata": {
        "id": "0c9356ba"
      },
      "outputs": [],
      "source": [
        "def main():\n",
        "    # The combined csv with all the high and low datasets will be named: combined.csv\n",
        "    defects_combined_path = Path(f'dataset/combined/combined.csv')\n",
        "    defects_df = pd.read_csv(defects_combined_path)\n",
        "\n",
        "    target_columns = [\"norm_homo\", \"norm_lumo\"]\n",
        "    defects_df_x, defects_df_y = props_targets(defects_df,target_columns)\n",
        "\n",
        "    # Split the data into train, validation and test sets\n",
        "    from sklearn.model_selection import train_test_split\n",
        "\n",
        "    # Assume df contains structures and properties\n",
        "    train_df_x, test_df_x, train_df_y, test_df_y= train_test_split(defects_df_x, defects_df_y test_size=0.2,\n",
        "                                        stratify= defects_df_x[\"dataset_material\"],\n",
        "                                        random_state=42)\n",
        "\n",
        "    train_df_x, val_df_x, train_df_y, val_df_y = train_test_split(train_df_x, train_df_y, test_size=0.15,\n",
        "                                        stratify= train_df_x[\"dataset_material\"],\n",
        "                                        random_state=42)\n",
        "\n",
        "\n",
        "    # Considering the train_df\n",
        "    # Going per row\n",
        "    for index, row in train_df_x.iterrows():\n",
        "        # Load defective structure\n",
        "        cif_id = row[\"_id\"]\n",
        "        dataset_type = row[\"dataset_material\"]\n",
        "        the_material = row[\"base\"]\n",
        "        defective_struct_path = Path(f'dataset/{dataset_type}/cifs/{cif_id}.cif')\n",
        "        defective_structure = Structure.from_file(defective_struct_path)\n",
        "\n",
        "        # Get reference structure\n",
        "        ref_file_path = Path(f'dataset/{dataset_type}/{the_material}.cif')\n",
        "        ref_unit_cell = Structure.from_file(ref_file_path)\n",
        "\n",
        "        # Get cell size\n",
        "        cell_size = list(ast.literal_eval(row[\"cell\"]))\n",
        "        reference_structure = ref_unit_cell.make_supercell(cell_size)\n",
        "\n",
        "        # get defects structure, and nodes and edges\n",
        "        defects_structure = get_defects_structure(defective_structure, reference_structure)\n",
        "        part_nodes, the_edges, the_edge_features = get_nodes_edges(defect_structure)\n",
        "\n",
        "        # Add global features to the nodes\n",
        "        global_columns = [\"energy\", \"fermi_level\", \"total_mag\", \"base\", \"vacancy_sites\",\n",
        "                        \"substituiton_sites\", \"formation_energy\", \"formation_energy_per_site\",\n",
        "                        \"energy_per_atom\", \"E_1\"]\n",
        "\n",
        "        global_vals = []\n",
        "        for n in global_columns:\n",
        "            global_vals.append(row[n])\n",
        "\n",
        "        the_nodes = []\n",
        "        for sub_list in part_nodes:\n",
        "            sub_list = sub_list + global_vals\n",
        "            the_nodes.append(sub_list)\n",
        "\n",
        "\n",
        "def props_targets(data_set, columns):\n",
        "    x_props = data_set.drop(columns, axis= 1)\n",
        "    y_targets = data_set[columns]\n",
        "    return x_props, y_targets\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "efzuIWLS3IIX",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "efzuIWLS3IIX",
        "outputId": "3611cc1d-c208-4d64-b1b3-af73fe6e0501"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "hello, world\n"
          ]
        }
      ],
      "source": [
        "print(\"hello, world\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b3d23eba",
      "metadata": {
        "id": "b3d23eba"
      },
      "outputs": [],
      "source": [
        "# Made the following changes in collabattempt branch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "836f6381",
      "metadata": {
        "id": "836f6381"
      },
      "outputs": [],
      "source": [
        "# This is a change made in the colab branch in vscode"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "OxUw7808luVH",
      "metadata": {
        "id": "OxUw7808luVH"
      },
      "outputs": [],
      "source": [
        "# Made this change in colab in the colab branch"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "MsProject",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.13.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}

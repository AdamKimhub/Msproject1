{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2507cdbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "if \"google.colab\" in sys.modules:\n",
    "    # Mount Google Drive\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    dataset_path = '/content/drive/My Drive/dataset'\n",
    "\n",
    "    # Install required packages\n",
    "    !pip install torch_geometric\n",
    "    import torch\n",
    "    from torch_geometric.data import Data, DataLoader\n",
    "\n",
    "else:\n",
    "    dataset_path = 'dataset'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5ad1311",
   "metadata": {},
   "source": [
    "## The data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7abbbf3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "# Training set\n",
    "train_graphs = torch.load(f\"{dataset_path}/combined/training.pt\", weights_only=False)\n",
    "\n",
    "# Validating set\n",
    "val_graphs = torch.load(f\"{dataset_path}/combined/validating.pt\", weights_only=False)\n",
    "\n",
    "# Testing set\n",
    "test_graphs = torch.load(f\"{dataset_path}/combined/testing.pt\", weights_only=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f635b07c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data loaders\n",
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "train_loader = DataLoader(train_graphs, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_graphs, batch_size=32, shuffle=False)\n",
    "test_loader = DataLoader(test_graphs, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f31e77f",
   "metadata": {},
   "source": [
    "## Build model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3f28737",
   "metadata": {},
   "source": [
    "### import dependancies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "698c87d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dependancies\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv, global_mean_pool, NNConv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e93db2b",
   "metadata": {},
   "source": [
    "### model class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "486ab583",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model 1\n",
    "class GraphLevelGNN(nn.Module):\n",
    "    def __init__(self, node_dim, global_dim, hidden_dim):\n",
    "        super().__init__()\n",
    "        self.conv1 = GCNConv(node_dim, hidden_dim)\n",
    "        self.conv2 = GCNConv(hidden_dim, hidden_dim)\n",
    "        self.fc1 = nn.Linear(hidden_dim + global_dim, hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, 1)  # For regression\n",
    "\n",
    "    def forward(self, x, edge_index, batch, global_attr):\n",
    "        x = F.relu(self.conv1(x, edge_index))\n",
    "        x = F.relu(self.conv2(x, edge_index))\n",
    "        x = global_mean_pool(x, batch)  # Aggregate node info to graph-level\n",
    "        x = torch.cat([x, global_attr], dim=1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        return self.fc2(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4638f5bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 2: Model considering edge features\n",
    "class GNNModel(nn.Module):\n",
    "    def __init__(self, node_dim, edge_dim, global_dim, hidden_dim):\n",
    "        super().__init__()\n",
    "        # Edge NN maps edge_attr to weight matrix\n",
    "        self.edge_nn = nn.Sequential(\n",
    "            nn.Linear(edge_dim, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, node_dim * hidden_dim) \n",
    "        )\n",
    "\n",
    "        self.conv1 = NNConv(node_dim, hidden_dim, self.edge_nn, aggr='mean')\n",
    "        self.conv2 = NNConv(hidden_dim, hidden_dim, self.edge_nn, aggr='mean')\n",
    "\n",
    "        self.fc1 = nn.Linear(hidden_dim + global_dim, hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, 1)  # Regression output\n",
    "\n",
    "    def forward(self, x, edge_index, edge_attr, batch, global_attr):\n",
    "        x = F.relu(self.conv1(x, edge_index, edge_attr))\n",
    "        x = F.relu(self.conv2(x, edge_index, edge_attr))\n",
    "        x = global_mean_pool(x, batch)\n",
    "        x = torch.cat([x, global_attr], dim=1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        return self.fc2(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7888a7eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GNNGraphLevelModel(torch.nn.Module):\n",
    "    def __init__(self, node_dim, global_dim, hidden_dim):\n",
    "        super().__init__()\n",
    "        self.conv1 = GCNConv(node_dim, hidden_dim)\n",
    "        self.conv2 = GCNConv(hidden_dim, hidden_dim)\n",
    "        self.fc1 = nn.Linear(hidden_dim + global_dim, hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, 1)  # For regression\n",
    "\n",
    "    def forward(self, x, edge_index, batch, global_attr):\n",
    "        x = self.conv1(x, edge_index).relu()\n",
    "        x = self.conv2(x, edge_index).relu()\n",
    "        x = global_mean_pool(x, batch)  # shape [batch_size, hidden_dim]\n",
    "\n",
    "        x = torch.cat([x, global_attr], dim=1)  # combine with global features\n",
    "        x = self.fc1(x).relu()\n",
    "        return self.fc2(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "080980e8",
   "metadata": {},
   "source": [
    "### model instance, optimizer, loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "223ecb4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate model, optimizer, loss\n",
    "\n",
    "# run the model in the gpu if the device has one\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu') \n",
    "\n",
    "# Instance of the model\n",
    "model = GNNModel(node_dim=8, edge_dim=3, global_dim=11, hidden_dim=32).to(device)\n",
    "# model = GNNWithEdgeFeatures(node_dim=3, edge_dim=1, global_dim=2, hidden_dim=64).to(device)\n",
    "\n",
    "\n",
    "# optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "# Loss function\n",
    "loss_fn = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dba21db1",
   "metadata": {},
   "source": [
    "### Train and validation loops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6588fcf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for data in train_loader:\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        # out = model(data.x, data.edge_index, data.batch, data.u)\n",
    "        out = model(data.x, data.edge_index, data.edge_attr, data.batch, data.u) # when added edg features\n",
    "        loss = loss_fn(out, data.y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item() * data.num_graphs\n",
    "    return total_loss / len(train_loader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dc04e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(loader):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for data in loader:\n",
    "            data = data.to(device)\n",
    "            out = model(data.x, data.edge_index, data.batch, data.u)\n",
    "            # out = model(data.x, data.edge_index, data.edge_attr, data.batch, data.u) # when there are edge fetures\n",
    "            loss = loss_fn(out, data.y)\n",
    "            total_loss += loss.item() * data.num_graphs\n",
    "    return total_loss / len(loader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8520aec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Training, validating, and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c2d8919",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run training and testing\n",
    "for epoch in range(1, 31):\n",
    "    train_loss = train()\n",
    "    val_loss = evaluate(val_loader)\n",
    "    print(f'Epoch {epoch:03d}, Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}')\n",
    "\n",
    "test_loss = evaluate(test_loader)\n",
    "print(f'Test Loss: {test_loss:.4f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MsProject",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
